{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions, layer_depth, layers = 1):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, layer_depth)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(layers):\n",
    "            self.layers.append(nn.Linear(layer_depth, layer_depth))\n",
    "        #self.layer2 = nn.Linear(layer_depth, layer_depth)\n",
    "        self.layer3 = nn.Linear(layer_depth, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        for i in range(len(self.layers)):\n",
    "            x = F.relu(self.layers[i](x))\n",
    "        #x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df = pd.read_csv('stockmarket_data.csv', decimal='.')\n",
    "df_dis = df[(df['stock'] == 'DIS')]\n",
    "df_msft = df[(df['stock'] == 'MSFT')]\n",
    "df_vow3 = df[(df['stock'] == 'VOW3')]\n",
    "df_jnj = df[(df['stock'] == 'JNJ')]\n",
    "df_r6C0 = df[(df['stock'] == 'R6C0')]\n",
    "df_date = df['Date'].unique()\n",
    "\n",
    "data = df.to_numpy().T\n",
    "\n",
    "companies = ['MSFT', 'VOW3', 'JNJ', 'DIS', 'R6C0']\n",
    "stockmarket_data = np.array([[[0],[0],[0],[0],[0],[0]]])\n",
    "bond_value = 1\n",
    "\n",
    "for i in range(len(df_date)):\n",
    "    date = df_date[i]\n",
    "    #print('date', date)\n",
    "    row_dis = df_dis[(df_dis['Date'] == date)]\n",
    "    row_msft = df_msft[(df_msft['Date'] == date)]\n",
    "    row_vow3 = df_vow3[(df_vow3['Date'] == date)]\n",
    "    row_jnj = df_jnj[(df_jnj['Date'] == date)]\n",
    "    row_r6C0 = df_r6C0[(df_r6C0['Date'] == date)]\n",
    "\n",
    "    if len(row_dis) * len(row_msft) * len(row_vow3) * len(row_jnj) * len(row_r6C0) != 0:\n",
    "        bond_value *= 1.00005\n",
    "        #print(np.array([[row_dis['Close'], row_msft['Close'], row_vow3['Close'], row_jnj['Close'], row_r6C0['Close']]]))\n",
    "        stockmarket_data = np.concatenate((stockmarket_data,\n",
    "                                            np.array([[[bond_value], row_dis['Close'], row_msft['Close'], row_vow3['Close'], row_jnj['Close'], row_r6C0['Close']]])), axis=0)\n",
    "    '''else:\n",
    "        print('date', date)\n",
    "        print('DIS', row_dis)\n",
    "        print('MSFT ', row_msft)\n",
    "        print('VOW3 ',row_vow3)\n",
    "        print('JNJ ',row_jnj)\n",
    "        print('R6C0 ',row_r6C0)'''\n",
    "stockmarket_data = stockmarket_data.reshape((len(stockmarket_data),6))\n",
    "stockmarket_data = np.delete(stockmarket_data, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spielumgebung definieren\n",
    "class stockmarket():\n",
    "\n",
    "    #Initialisierung des Spiels\n",
    "    def __init__(self, stockmarketdata, start_budget, last_day):\n",
    "        self.stockmarketdata = stockmarketdata\n",
    "        self.start_budget = start_budget\n",
    "        self.budget = start_budget\n",
    "        self.day = 0\n",
    "        self.num_days = len(stockmarketdata)\n",
    "        #self.actionspace = np.array(range(2**len(stockmarketdata[0])))\n",
    "        #self.actionspace_length = 2**len(stockmarketdata[0])\n",
    "        self.actionspace = np.array(range(len(stockmarketdata[0])))\n",
    "        self.actionspace_length = len(stockmarketdata[0])\n",
    "        self.last_day = last_day\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        reward = 0\n",
    "        roi = 0\n",
    "\n",
    "        '''#action aus 0-64 in array aus 6 Nullen und Einsen umwandeln -> 0 = nicht gekauft, 1 = gekauft\n",
    "        portfolio_action = []\n",
    "\n",
    "        for i in range(self.actionspace_length):\n",
    "            portfolio_action.append(action % 2)\n",
    "            action = math.floor(action / 2)'''\n",
    "\n",
    "        self.day += 1\n",
    "\n",
    "        if self.day == self.num_days or self.budget == 0 or self.day >= self.last_day:\n",
    "            #run is over\n",
    "            terminated = True\n",
    "\n",
    "            return np.array(self.state), 0, terminated\n",
    "        else:\n",
    "            #Profit berechnen\n",
    "\n",
    "            '''for i in range(len(self.stockmarketdata[0])):\n",
    "                reward += portfolio_action[i] * (self.budget * (self.stockmarketdata[self.day][i] / self.stockmarketdata[self.day - 1][i]) - self.budget)\n",
    "\n",
    "            if sum(portfolio_action) > 0:\n",
    "                reward /= sum(portfolio_action)'''\n",
    "            \n",
    "            reward = (self.budget * (self.stockmarketdata[self.day][action] / self.stockmarketdata[self.day - 1][action]) - self.budget)\n",
    "            roi += (self.stockmarketdata[self.day][action] / self.stockmarketdata[self.day - 1][action])\n",
    "\n",
    "        reward = np.float32(reward)\n",
    "\n",
    "        #reward -= self.budget\n",
    "\n",
    "        self.budget += reward\n",
    "\n",
    "        #print('reward ', reward)\n",
    "        #print('budget ', self.budget)\n",
    "\n",
    "        #self.state = np.concatenate(([self.budget],self.stockmarketdata[self.day]), axis=0)\n",
    "        self.state = self.stockmarketdata[self.day]\n",
    "        \n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated\n",
    "\n",
    "    def reset(self):\n",
    "        #state = [budget, stockmarketdata]\n",
    "        #self.state = np.concatenate(([self.budget],self.stockmarketdata[0]), axis=0)\n",
    "        self.state = self.stockmarketdata[0]\n",
    "        self.day = 0\n",
    "        self.budget = self.start_budget\n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = stockmarket(stockmarket_data, 100, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal reward:  133.90689013814912\n",
      "lazy reward:  101.21084889652583\n"
     ]
    }
   ],
   "source": [
    "#calculate optimal and \"lazy\" reward\n",
    "optimal_reward = env.start_budget\n",
    "lazy_reward = env.start_budget\n",
    "\n",
    "upper_bound = min(len(env.stockmarketdata), env.last_day)\n",
    "\n",
    "for t in range(upper_bound):\n",
    "    if t == 0:\n",
    "        t = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    for i in range(len(env.stockmarketdata[0])):\n",
    "        #lazy reward picks bond + all stocks equally\n",
    "        lazy_reward += (1 / env.actionspace_length) * (lazy_reward * (env.stockmarketdata[t][i] / env.stockmarketdata[t - 1][i]) - lazy_reward)\n",
    "\n",
    "        #optimal reward stock/bond with biggest reward\n",
    "        reward = 1 * (optimal_reward * (env.stockmarketdata[t][i] / env.stockmarketdata[t - 1][i]) - optimal_reward)\n",
    "\n",
    "        if reward > max_reward:\n",
    "            max_reward = reward\n",
    "\n",
    "    optimal_reward += max_reward\n",
    "\n",
    "print('optimal reward: ', optimal_reward)\n",
    "print('lazy reward: ', lazy_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.099\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.actionspace_length\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "layer_depth = 1000\n",
    "layers = 1\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions, layer_depth, layers).to(device)\n",
    "target_net = DQN(n_observations, n_actions, layer_depth, layers).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[np.random.choice(env.actionspace)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "episode_returns = []\n",
    "episode_returns_averaged = []\n",
    "lazy_bound = []\n",
    "optimal_bound = []\n",
    "EXPONENTIAL_AVG_FACTOR = 0.02\n",
    "\n",
    "\n",
    "def plot_metrics(show_result=False):\n",
    "    plt.figure(1)\n",
    "    returns_t = torch.tensor(episode_returns, dtype=torch.float)\n",
    "    returns_avg_t = torch.tensor(episode_returns_averaged, dtype=torch.float)\n",
    "    lazy_bound_t = torch.tensor(lazy_bound, dtype=torch.float)\n",
    "    optimal_bound_t = torch.tensor(optimal_bound, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Returns')\n",
    "    plt.plot(returns_t.numpy(), '+')\n",
    "    plt.plot(returns_avg_t.numpy())\n",
    "    plt.plot(lazy_bound_t.numpy(), 'r--')\n",
    "    plt.plot(optimal_bound_t.numpy(), 'g--')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    '''\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())'''\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "    #print('model got optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (layer1): Linear(in_features=6, out_features=1000, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  )\n",
      "  (layer3): Linear(in_features=1000, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(policy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "EPS_START = 0.9\n",
    "EPS_END = 0.0005\n",
    "EPS_DECAY = 2000\n",
    "EXPONENTIAL_AVG_FACTOR = 0.02\n",
    "print(EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "current greed rate:  0.6034528814090576\n",
      "current avg reward:  104.23079829137069\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGDCAYAAADDDq+xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCz0lEQVR4nO3deZxcZZn3/8/VnXT27hCS7rAECFs0gLKjwoCKGRWcERVERdzGBUVGRJ0BZ0HxN8qDDugDOPMoyuKggiMyA4pI2ATEsK8BQyAQsnYW0p2l975+f9yn0pVKVXVVdW2nzvf9ep1XV51z16m7TnWdc517NXdHREREJEmaap0BERERkWpTACQiIiKJowBIREREEkcBkIiIiCSOAiARERFJHAVAIiIikjgKgERERCRxFACJiIhI4igAEhERkcRRACQiUmVm5mb2jVrnQyTJFACJSMMxs09EQUZqGTSzlWZ2jZntUev8ZTKzt5jZN8xseq3zIpIU42qdARGRCvpXYBkwEXgT8AngODM72N17a5mxDG8BLgSuATbVNCciCaEASEQa2W3u/kj0+CozWw/8I/C3wI21y5aI1JqqwEQkSe6L/u6XWmFmrzOz/zazjWbWa2aPmNnfpr/IzMab2YVm9kKUZoOZ3W9mC9LS3GNm92S+YVTt9nKuDEVtgb4bPV2WVm23T8mfUkRGpRIgEUmSfaK/rwGY2UHAA8BK4GJgK/BB4GYz+4C7/yZK/w3gAuAq4CGgFTgSOBy4Y4x5ugk4EPgw8GVgfbR+3Rj3KyJ5KAASkUbWZmYzCW2AjiG0s+kDbo22/wBYDhzl7n0AZvZD4H7g/wCpAOhk4Hfu/tlyZ9DdnzKzxwgB0M3u/nK530NEdqYqMBFpZAsJJSmvAv9NKOH5W3dfYWYzgLcT2gJNM7OZUbC0K3A7cEBaj7FNwEFmdkC1P4CIVIYCIBFpZGcDC4BTgd8BMwklQAD7AwZ8ixAkpS/fjNK0R3//FZgOLDGzp83su2b2hmp8ABGpDFWBiUgjeyjVC8zMbiZUbf3czOYxcgP4PUKJTzZLAdz9j2a2H/Be4K+BTwNfNrOz3P2qKK0TAqpMzeX4ICJSXgqARCQR3H3IzC4A7ga+CPw02jTg7gsLeP1G4GrgajObCvyR0Dg6FQC9Buyb5aV7F5K9AtKISBmpCkxEEsPd7yH04joX6AbuAT5nZrtlpjWzWWmPd83YzxZC6dCEtNUvAq/LeN0bgWMLyNrW6O/0AtKKSBmoBEhEkua7wK8Io0KfTagWe9rMfgy8BHQAbwb2BN4YvWZxNMbPo8BGQhf4U4Er0vb7U+A84HYz+wmh/dBZwLOEbvP5PBr9/Tcz+yUwANzi7lvzvEZExkAlQCKSNDcRSmu+CvyFEMz8lhAQXUkIWoaBi9Je838JYwhdED0+Afhn4CupBO7+HPAxoA24lDDa9JnAY6NlyN0fBv6FEHBdA/wCmJXvNSIyNuauqmcRERFJFpUAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwNhFhnzMyA3YHNtc6LiIhIDE0DVvko4/woAKo/uwMrap0JERGRGNsTWJkvgQKg+rMZ4NVXX6W1dbTR80VERCSlu7ubOXPmQAG1KAqA6lRra6sCIBERkQpRI2gRERFJHAVAIiIikjgKgERERCRxFACJiIhI4igAEhERkcRRACQiIiKJowBIREREEkcBkIiIiCSOBkJMiK39W3Nua25qZuK4iQWlbbImJo2fVFLabQPbyDU1i5kxefzkktL2DPQw7MM58zGlZUpJaXsHexkaHipL2snjJxOmeYO+wT4GhwfLknbS+Ek0WbiP6R/qZ2BooCxpJ46bSHNTc9FpB4YG6B/qz5l2wrgJjGsaV3TaweFB+gb7cqZtaW5hfPP4otMODQ/RO9ibM+345vG0NLcUnXbYh+kZ6ClL2nFN45gwbgIA7s62gW1lSVvM717niOxpdY4Y+zki/RhVmwKghJj6nak5t510wEn89iO/3f68/XvtOU+cJ+x9Avd84p7tz/f5wT6s37Y+a9ojdz+Shz/z8Pbn86+czytdr2RNO3/WfJ79wrPbnx/146NYvG5x1rR7t+3Ny+e+vP358dcczyOrHsmadubkmaz72rrtz999/bu595V7s6adPH4yW78+crL+wI0f4Hcv/C5rWgC/cOTke+ZvzuS/F/93zrRbLtiy/Yf+uVs/x7VPXpszbedXO5k1ZRYA591+Hj985Ic50y770jL2mb4PAP905z/xvQe/lzPtM59/hoPaDwLg2/d9m2/e+82caR/69EMctcdRAPzgzz/gHxb+Q860d3/8bt66z1sB+NGjP+KLt30xZ9pbP3wrJx94MgDXP309n/yfT+ZMe+OpN3LaQacB8JvnfsMH//uDOdNe/d6r+cShnwDg9qW3855fvCdn2ivefQVnH302APctv4+3Xfu2nGkvecclfO3YrwHw2OrHOPqqo3OmvfCEC/nGW78BwHPrnuPg/zg4Z9qvvvmrfPevvwvA8q7lzP3B3Jxpv3DkF7jy5CsBWL9tPe3fa8+Z9uNv/DjXnHINEAKEfL/7U+efyq9O+9X25zpHBDpHVPcckX6Mqk1VYCIiIpI4Nsps8VJlZtYKdHV1dZV1LjAVbxefVsXbqgJTFVjxaXWOKC1tUs8R5a4C6+7upq2tDaDN3bvzpVUAVGcqFQCJiIg0umICIFWBiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgKgCjKzOWZ2j5ktNrOnzOy0WudJREREYFytM9DgBoFz3f0JM5sNPGpmv3P3rbXOmIiISJIpAKogd18NrI4erzGz9cAMQAGQiIhIDdW8CszMjjezW8xslZm5mZ1SwGs+H1UpdUfLg2b27lrkzczONrOXzazXzBaZ2dE59nUE0Ozur5Y7nyIiIlKcmgdAwBTgSeDsIl6zAjgfOAI4ErgL+B8zOyhbYjM71szGZ1k/38w6Ss2bmZ0OXAp8Ezg8Snu7mbVnpJsBXAd8dpTPJSIiIlVg7l7rPGxnZg68z91vLuG1G4GvuftPMtY3AY8BLwAfcvehaP084F7gUne/pJS8mdki4GF3/2Lae70KXO7uF0frJgB3AD9295/l2f/ZhECrCZjX1dVFa2troR9fREQk8bq7u2lrawNoc/fufGnroQRoTMys2cw+RCiteTBzu7sPAycBhwHXmVmTme1HKDW6uZDgJ8f7thBKoBZmvNdC4M1RGgOuAe7KF/xEr73S3ecDWavQREREpHxiGwCZ2SFmtgXoA/6TUDqzOFtad18FvB04Dvg5IfhZCHx+DFmYCTQDazPWrwVmR4+PBU4HTjGzJ6LlkDG8p4iIiJRBnHuB/QU4FGgDTgWuNbMT8gRBy83sTEK110vA33mF6//c/X5iHGSKiIg0qthenN29392Xuvuj7n4BoQHyl3Kljxo7/wi4BZgMXDbGLKwHhoDMRtQdwJox7ltEREQqKLYBUBZNwIRsG8xsJnAn8BzwfuBE4HQz+16pb+bu/cCj0b5S79MUPd+pLZKIiIjUj5pXgZnZVGD/tFVzzexQYGNUbfVFQvue9EDjO8BtwHJgGvAR4K3AO7PsvylK+wpwursPAovNbAFwl5mtdPespUGj5Y3QBf5aM3sEeAg4l9AY++pij4OIiIhUT80DIMI4PnenPb80+nst8AlCY+P9Ml7TThhXZzegC3gKeKe735G5c3cfNrOvA/dFpTap9U+a2TuAdaXmzd1vMLNZwEWEhs9PAO9y98yG0SIiIlJH6mocIAEzawW6NA6QiIhIcRI1DpCIiIhIsRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQBUQWY2x8zuMbPFZvaUmZ1W6zyJiIgIjKt1BhrcIHCuuz9hZrOBR83sd+6+tdYZExERSTIFQBXk7quB1dHjNWa2HpgBKAASERGpoZpXgZnZ8WZ2i5mtMjM3s1NGSX+BmT1sZpvNrNPMbjazebXKl5mdbWYvm1mvmS0ys6NzpDsCaHb3V8udVxERESlOzQMgYArwJHB2gelPAK4E3gQsAMYDfzCzKbleYGbHmtn4LOvnm1lHqfkys9OBS4FvAodH6W83s/aMdDOA64DP5vlcIiIiUiXm7rXOw3Zm5sD73P3mIl4zC+gETnD3P2bZ3gQ8BrwAfMjdh6L184B7gUvd/ZJS8mVmi4CH3f2Lae/1KnC5u18crZsA3AH82N1/luc9ziYEW03AvK6uLlpbWws4AiIiIgLQ3d1NW1sbQJu7d+dLWw8lQGPVFv3dmG2juw8DJwGHAdeZWZOZ7QfcBdw8WvCTi5m1AEcACzPeayHw5iiNAdcAd+ULfqLXXunu84GsVWgiIiJSPrEOgKISl+8DD7j7M7nSufsq4O3AccDPCcHPQuDzY3j7mUAzsDZj/VpgdvT4WOB04BQzeyJaDhnDe4qIiEgZxL0X2JXAwYTAJi93X25mZxKqvV4C/s4rXP/n7vcT8yBTRESkEcX24mxmVwDvAd7m7isKSN8B/Ai4BZgMXDbGLKwHhoDMRtQdwJox7ltEREQqKHYBkAVXAO8D3u7uywp4zUzgTuA54P3AicDpZva9UvPh7v3Ao9G+Uu/TFD1/sNT9ioiISOXVvArMzKYC+6etmmtmhwIbo2qrLxJ6YKUCjSuBjwDvBTZHIywDdLl7T5b9NwG3Aa8Ap7v7ILDYzBYAd5nZSnffqTRotHxF6y4FrjWzR4CHgHMJ3eevLvY4iIiISPXUPAACjgTuTnt+afT3WuAThMbG+6VtTzVcvidjP58k9LjagbsPm9nXgfuiUpvU+ifN7B3AuhLzhbvfEHXDv4jQ8PkJ4F3untkwWkREROpIXY0DJGBmrUCXxgESEREpTtLGARIREREpigIgERERSRwFQCIiIpI4CoBEREQkcRQAiYiISOIoABIREZHEUQAkIiIiiaMASERERBJHAZCIiIgkjgIgESlJZ3cvl92xhM7u3lpnRUSkaAqARKQknZv7+MGdL9C5ua/WWRERKZoCIBEREUmcepgNXkRiorO7d3uJzzMru3b4C9A+bQLtrRNrkjcRkWIoABKRgl2/aDk/uPOFHdadf9PT2x9/6cQD+PKCA6udLRGRoikAEpGCnXHMXiyY3wGEkp/zb3qai99/CAfv0QaEEiARkThQACQiBWtvnbhTFdfBe7RtD4BEROJCjaBFREQkcRQASdVo3JjG0j5tAl868QBVe4lILCkAkqrRuDGNpb11Il9ecKB6fYlILCkAEhFpcCp9FdmZGkFLRWncGJHaS5W+Lpjfod+bSEQBkFSUxo2Rcuvs7uX6Rcs545i9dDEXkZIpAJKK0rgxUm4qzSiMSl9F8lMAJBWlcWNEakOlryL5KQASkbqn0oziqfRV6l2tq7MVAEnVaNwYKZVKM4qn0lepd7WuzlYAJFWTGjdGpFgqzRCRclMAJCJ1T6UZY6PSV6kX9VSdXVIAZGaTAHP3bdHzvYH3AYvd/Q9lzJ+IiIyRSl+lXtRTdXapJUD/A9wE/KeZTQcWAQPATDM7z93/o0z5ExHZgUozROKrnqqzSw2ADge+HD0+FVgLHAZ8ALgIUAAkIhWh0gwpVq17G8mIeqrOLnUusMnA5ujxXwM3ufsw8Gdg73JkTEREpBw0EbNkU2oAtBQ4xczmAO8EUu1+2oHucmRMREREGletq7NLrQK7CPg5cBlwp7s/GK3/a+DxcmRMRESkVPXU20iyq3V1trl7aS80mw3sBjwZVX9hZkcD3e7+fPmymCxm1gp0dXV10draWuvsiIjE0mV3LNmpt1E6DZ7ZmLq7u2lrawNoc/e8NVIlB0BSGQqARETGLrMEKFtvI5UANZ5iAqBSxwGaApwPnEho97NDWyJ337eU/YqIiJRDPfU2kvpUahugq4ATgJ8BqwEVI4nEiLoFi0jSlRoAvRs42d0fKGdmRKQ6aj0JodS3RguQa93bSOpTqd3gXwM2ljMjIiJSHxpt3JxUb6NGCOakfEotAfoX4CIz+3hqPjARqW/qFiyV1GilRtL4Sg2AvgLsB6w1s5cJ84Bt5+6HjzFfIlJm9TQJodSfsQbIqlaVuCk1ALq5nJkQkcqrp0kIpf4oQJakKToAMrNxhF5fP3X3FeXPkohUgroFSz6lBMiqVpU4KzoAcvdBM/sacF0F8iMiIjVQSoCsUiOJs1KrwO4ijAP0cvmyIiLVom7BUg6qVpU4KzUAug242MwOAR4FtqZvdPf/HWvGRKRyaj0JodS3QgNkVatKnJUaAP0w+ntelm0ONJe4XxERqTEFyJIEJQ2E6O5NeRYFPxEzm2Nm95jZYjN7ysxOq3WeREQqQdWqEjeaDb6CzGw3oMPdnzCz2YTqwgPdfWue12g2eBERkRJUYzb4f8233d0vKmW/jcbdVxMmi8Xd15jZemAGGW2mRERkZxpdWiqp1LnA3pexfBD4R8II0acUsyMzO97MbjGzVWbmZjbq60t5TSkKeR8zO9vMXjazXjNbZGZH59jXEUCzu79aibyKSOE6u3u57I4ldHb31jorNRGXz99oc5JJfSm1DdBhGcvBwG7AncBlRe5uCvAkcHalXmNmx5rZ+Czr55tZR6nvY2anA5cC3wQOj9LebmbtGelmEMZN+mwh+RWRykr6hTXpn18ESu8FthN37zazC4FbgJ8V8brbCN3qMbOyv8bMmoArgRfM7EPuPhStn0cYz+hS4JIS3+c84MfufnWU5izgZOBTwMXRugmEqUMudvc/5cnn2YRAq9RSORGR2NPo0lItZQuAIm3RUjfcfdjMTgL+CFxnZmcCcwnBz83unjX4GY2ZtQBHAN/JeK+FwJujNAZcA9zl7nmDQne/Ergy1Qi6lDyJSG5Jv7DG5fNrdGmpllIbQf995ipCFdiZRCUm9cTdV5nZ24H7gJ8TApSFwOfHsNuZhPGO1masXwu8Lnp8LHA68FRa+6Ez3f1ppGzUUFIKkfQLa1w+v0aXlmoptQToyxnPh4F1wLWklYjUE3dfHpX+3Au8BPydV3gMAHe/H1VpVVyqPcOC+R0KgCSnpF9Y4/L5Nbq0VEtJAZC7zy13Riotauz8I0IbpaMIjbXPGcMu1wNDQGYj6g5gzRj2K2OkEiHJJukX1qR/fpFMJZVOmNlPzWxalvVTzOynY89WeZnZTEIPteeA9wMnAqeb2fdK3ae79xMGNjwx7X2aoucPjinDMqrO7l6eWdm1fQG2P/7TixvUw0WkwqrRlV6jS8dHXIZWSFdqFdjHgfOBzRnrJwEfI/SCKoiZTQX2T1s118wOBTZG1VZfBN7n7icW+pqM/TcR2iW9Apzu7oPAYjNbANxlZivdPWvX/QLe51LgWjN7BHgIOJfQdf7qQj+/lGa09gwi+ST9wlqOz1+NqudqzUmmUuOxi2NThKICoKiHkkXLNDNLD/WagZOAziLzcCRwd9rzS6O/1wKfIDQ23q/I12wX9cz6OnBfVGqTWv+kmb2D0HappLy5+w1mNgu4CJgNPAG8y90zG0ZLmWVrz3DO2/Znv/apvLhuC5fftbQue7hIfWikyT5LuXg30ucvhzhevGXsii0B2kSY7d2BJVm2O3BhMTt093sIAVWu7d8AvlHMa7Ls444c6x8fS96iNFcAVxSaFymPbO0ZLr976Q7P67GHi0i5VfPiHZeu9FIdcf9/KDYAehshILgL+ACwMW1bP/CKu68qU95EivL90w9l//apdd3DRaTSKlmdE5eu9IWox4t33Kri4v7/UFQA5O73ApjZXGB5pbuRixQi1Z7hLfvtusNJQz1cpFHlu3gv7dxSsRKhuHSlL0Q9XrzjVhUX9/+HUrvBv2Jmf2VmnwP2BU5z95XRODvLovFvRKpC7RkkaWrVCaCRutLX4uIdtxKe0cT9/6HUkaA/QJjv63rCJKCp/5Q24OuExtAiNVEvPXwa7WQn9SOunQDq6TdRi4t3thKeeqyKS4pSu8H/M3CWu19nZh9KW/9AtE2kZuqlRChuxdkSH/XQCaCUGw39JnZWj1VxpaiXG89ilBoAzSNMLpqpC5hecm5ERKQk1e4EUC83GuVQyYv3aCU87zyoI9btaFLi+P9QagC0hjBA4MsZ648jzLMlkkgqzpZqq/dOANX+TdTbuEillPDUy3fX6EoNgH4M/MDMPkUY+2d3M3sz8O+EQQFFEqlRirMlPur9zrvav4l6q2aLe0+pRlZqAHQxYR6xO4HJhOqwPuC7wFXlyZpI/OhkV17laDRbTw1vq6He2mIk/TdRTGPrevvuGl2p3eAd+Dcz+y6hKmwqsBj4HLCMMC2ESOLEvVtovSnH3Xwh+ygkSIpLIFWpEqFSP381fhONUvVc76V5jabYucAmEKalWEBU4uPuN5vZJ4HfAENA1olFpb7E5WQuUg0FBUl1VrVSbfX8+eNS9awSnvpSbAnQRYRSnoXAW4BfmdnVwJuArwC/cveh8mZRKqGeT2a1UImAUCe70hR7N5/tu2uUEoFGU6nfRFyq2apRwlOtm9tGuIkuNgA6DfiYu/+vmR0MPBXt442aFkOqpRI/vEoEhCrO3lkh312xd/PZvrtC9nHGMXuNGiSl9p8vTVxP/oUodyBZqd+Eqp5HVOvmthFuoosNgPYEHgVw92fMrA+4TMFPPDTKXXEj/PDGIs53XoV8d+W4my9kH4UESUAsqlYqJS5VSyKlKDYAaibM+p4yCGwpX3akkpJ6MssVMMQ1IGz0ALCQu/lCvrvMu//MfRQaaMWhaqVS4lK1lK5aVc/1dCNSrXNZXM+ZuRQbABlwTVTyAzAR+E8z25qeyN3fX47MSXnF8WSWMpYfXq6AIakBYbVV4qRZju+u0GqTWlat1PoiW+2qpXJ83mpVPdfTjUi1zmWNds4sNgC6NuP5f5UrI1J5ca4nr8QPL04BYZzvvMby3eW6my/mu4tTY/TMAKCeLrLVkLTPWy7VOpfF6ZxZiKICIHf/ZKUyIpJPsT+8QgOGuASEowURx8ydweUfPqwuBwscy0kz1918UYPLFVAiUEiQVI1Aqp4DgDgFkpVSrzci5T6X5TofxOmcWYhSR4KWmIvbyazYH16jFdXmCyKWdm7h3BueoHNzX0UHCyxVHE6aBQVJVezVt7QzNK2st4tspQZYrMegIptGOa+MdsNTz4F4OSkASqhG76JdbKlDvTecjEMQUStxCuYLHbPo3Bue2OF1cbzIFipOQUUcqoAK+T2UI8CJ0+8uFwVAEjsFVVeMEjB0dvdy2R1Ltl+I4thwcqylBLW4867ESTNOwXyhYxZlqreLbDnFIahIqVZV01iU+nso9nwQp99dLgqApK5lO0GU44c3WiBS6943+bRPm8Axc2eMuZSgFnfejXDSLLdCqjcbubQvyaWb1axqGi3AufnxlVx1/7IdXlOvJXHlogBI6lqtimrLeWKqxGi6l3/4sB32WanBAmXsyjFmkdSfuFUBjXbD8+nj5nLrOccB2c8HTcYOpeaNQAGQNLxUqUNnd+9OF6BqNLasRElLOe6ak3znXU2VGAagUcXp81arqqlcCrnhyXc+eGZlV8M1jFYAJDVVzYksC7kDOuWwPcr+vippSbaxjFmUtCrDJHzeWjX61g3PzhQASU2VOpFlKSeI0S5ENz++kvdcfn/Z37fSJ55y3DXH6c47bso9ZpHUp0LbDY71hqga7RNT54Mm2/lmsF6HKCiFAiCpO5UqMRntQtQ+bcIOJUCFDLZYDw2ly3HR1IVXZGwKbTc41huiarSLTJ0PLrtjSWyGKCiFAiCpunptFFrsiamUE5FKWpJN37/Ug0JveMp9M1ovN40pCoCk6uph4LNaXYhU0pJs+v6LsHU9rHkaulfCPn8Fu+xd6xztZKztFQs9D9Wq4XTZxz1Kv2kcWgvP3wqdi+G9V5Yju0VTACRVVw8TWY52Icr1vnEatl+kqoYGobcLmpqjZRwMD0H3KuheAV0rYfOakLZ5PIybEP4ODULfZujrDn+7V4bAZ/PqHfe/97HwhtPhoFNgYhEX4A0vwuonYM4x0LZnuT4tMPabuUID4krPBThmvd2wYWkIWpuaw/fa3AJN48FSiYxJa1/jnOab2O+mb8OGZ0Zef/zXYJd9qp5tc/eqv6nkZmatQFdXVxetra21zk7FPbOyi/dcfj+3nnNcLHojZKsTTxf3OnGRgg30wMrH4JU/wSsPwKsPwcDW8r7HjH1h8q6w4hEgulY1T4B93wr7vR32PxF23R8susq6Q89rsOYpWPIHeOH2cGEGsCaYdxIc/RmYe8LIa/q3hiCpfwtMnB6Cq0nTYfzkkTQ5ZN4Qjdq1vLcrBHkDPeF9B3pgyxp47eWwbFwW8jHzQJj1Omh/Pcw8gPXbhtmweRs2PMTStV1cesdfOG/BPPbvmMbyDT1cetuTXHnKXsyd1Avb1od9T5kJU9phagdM2TUEmv1bYGBb2N7cApNnwKQZ4W9zS9jetyXksX8rDPbCUB8M9tO1eTMPPfcSb94Npg51w7aNsGk5bHgBtqwt+qt1a2Lb7KMZnncy047+aMhDGXR3d9PW1gbQ5u7d+dIqAKozCoDqW9EnPJG4Gh4Kd/Rb1sKWTti8Cta/AOuXhOW1l8GHR93N0PhpNE/fE1p3h9bdwJphqD8sg32htGBCK0yYFv5OmQkdB0PH/LAOQunR0zfCkzfAuud2fIO2OaFkp3tVKGEa6ttxe9O4ECSte35k3cwDYdpuITjqXpk9480TYGoUQEztCPka7IWeTdC7KQRag73hOA0PMTg4wIaeIVp33Z1J0zvCa1umhpKsTcvD0pf3ehxvUztg2mwYHobhAQYH+tjW04M7bOkb2J7s+eG9uH34SBYOHcFGWst+01hMAKQqMKmpuDUK1VgaEntDg7DxxVAiMnnXUOrR1AT922D5g7DsXnjp3lAN5UP59zW1A/Z+C+z1lvB31usAh+FBFq/YyKn/78/c+Jl35O5IUGij2LY94Lgvw7HnhjYjSxfCi3fBKw9C16thSTdt91BCdOBfw75vg4mt0PkcPHwVPPnLkSAuZdKMUOrT2xUCHB8KgVS2fecwDugwYOMm2Lg4d8LmFhg/KZQwjZ8UvoNd5oYqoBlzw/r1S0J+1z0PG18KJVtN46BpHIMYm3sHmdLSRFOTMTw0TNdAE+OnzWJcazuDE3dlwqQpTBroGglet60PAV3LZGiZEt5jqD+U4vRshOHBkfw1jYcJU0PwNm5iVFXZEv5OnB7yOzkqNZq2O8zcPwSYGdWSz0c3t9d96mhmTGkBdrxp/FgdjIOmAEhqSo1CRSps20Z44Q+humrV4yGwGewZ2W7N4aLWuylcFHdgMGUWTItKQWbsBzMPgFnzQinK1I4dqol2KCFdN8Q2JuZtI1d0T0oz6DgoLMd+aSRo6+0KJUzTdgulEOOyXFTbXw8n/zuceGFofOsePsuu++9Y/eIeqoK2bQzBw5a1oZpq64YQsEyaHgKBVDVZUzNYMxt6hvj9k8s5ed/xTPcu2LoulPhM2w2m7w3T54TSqpbJo3/OPDZ293LOLx5n0bKNO27oA9aHh0WVqriHKq+h/lDilu3YjcGMKS11O9WLAiCREsWt9Cop6q2rbU0MDcALd8CTP4e//B6GB3bc3jI1BD59XaG0Y2tnWN+6J+x7Qmgjs/dbwsW7ufDLRNV7eLZMDu2AijGxFQ79SO7tZlF13LSiep7tCpyx72HF5aUE5ZoLcDuzcEzKYLROIhu39mV9Xa0oABIpUTVKr3QxL141Z9iuCwO9oSHq+iWwbgms/wssuy9Ue6R0HAJzj4fdDwvLjH1DtddgH2zbENr6TJgaqmJGafibTyE9PNWTcuzqtSq+kOmG6ummUQGQSB1L3MW80vq2wKrHYOWjoRFv14qRpak5VOvMnBeqRqbMCg1/U9u3rA1VH6lGsdM6QprJu8LkmaGnzdSOUE1SquHhUBW1pTOUymzpDM+tKbTNaBoXApSNy0JbmM7FURuRLI2Rp7TDGz4YSjs6Dsr+fuMmRI2Tdy89z2kKuTA3+ujCSVbKhKu1pABIpABJL4mp98+fWaowhR5efe4hpr38Gi2bX2X61mVM6nwCOp/N33NpxcNhGYvJu4ZeSW1zorY1XaGhac9r0NMVgo4JU0MVS8u00B5n6zrYsi6U2qQ3SC3UxOkj7XJmzQu9qPb5q6Kqr6pFkwOXVz1VxddryVQu9ffrEKlD1SyJqccqgropiXrtFXjuf0OpR9cK2PQqdK1gZv9WZrrTZM7BwIcmAvfn2EfbHNjzyNBjqXWPKFjZMzQC3V6NtCRUDaVvn9oRgpkta0Jp0Oa1IWDZtiE0kN22PnSL3rYhLKufLP1zTpweulFPaYfJu4SGqkMDMDxI/0A/S3qns/frj2TaXm+A9vk7NUauB7kuzHG7SNY7dSQpnQIgkTpTD1OFjKprBTx1Y+gFs/thMPuQknq3FFSyNNgHz/8WHrsOXrqH7QPipWmCtBFng77x0xlq24uBaXMYN3Nfpsw9CvY8OoxFk0uuqqJC9WxKq1Z7NZT6TGyLulnvEh4P9aUNNrc5dDWe0h7GmZnaHqrTxrXkfIslqbGz3lvfY2fpwpxs9VQylYsCIJEcalUSUy9VBNk+/4rnHmLPu6+n7cVbME+rqrEmmPX6EEDssjdM3yssE9vCIHabloeAoHtlVAVlYMaE3iHal/TgvW+EPeaGXkcQSng2vhRG6F35aKhCSpl7Auz1ppGSmdY9R8YgMeO5NZs59arHueEzC6ofIEyaHpbZB1f3fWMqDhdJKU0cAmAFQCI51KokpuJVBO5hkLVNy0Mj381rwmi1A73RYGthHqfVK7t5ZsUmDMdw/mt8J8fd/+z23bzaejhzZneERsVb1ob2NZ3P5nnjnbUBZ4wDHr0THs2TcNrucNhH4bAzRp0zaGjSBLYyhobIdageq0XLIQ4XSWlcCoBEchhTSUzfltBDZ8PSEGBs6QxtR7ZtDFUdrXtE7Uv2CG1RZuwXuiWPxj30CupeFS0rw18sbYC2XcLAbqlh/MdPCqP/Ln8QnrslVCd1rxj1rd4IvDHjDDFME937nsz6N3yW1n2PhtaJIU+bV4eB9ja8MDLs/6bloUqobc+REqG2Penuhy29/eDDrN60jfufWsJ75hrtvMa4rWsY3+SMm7lf6Ko9Y9/QqHfOMSEwK0AjlirEolq0gdR7o38pD80FVmeSNhdYXRkeDg1ZUw1cezdF8/wMsHLjZv7fXc9x9ptm0TG+J7TtSHVPHjcRxk+EcZNCkLPmGXhtWXHv3TINdj80LG1zQoPXoX62bOvh+VdWcvDkTUzcshxeWx4GryvGhKjkKP1146eErt6tu4eRc6ftFtrz+BAMD7J201Z+sWgZHz5mHzpaJ7F2cz8/fnAVp330LOa9/g3FvX8GTShbPM1BV11xm6NQRmguMJFshodCd+PNq0OpSaqNycYXw7gq3atyzn20B3DRePJX02SaOjuUXrTuPjJR4KRdwqBz3StHGsp2Ph8aw758X1jSdwEcmW3fk2aMlCBN2y30AOrZNBKYbdsQSp0Ge0cCn0m7wLyT4fXvCbNp5xmvZt3KLr7/wP284/Dj6NijjXUru7jq/vs5pbXwkXFzqZc2TnGinlNSSUkt8VIAJI1leDhtgLhloSTmtZdD9+kta0ef3DE199HUjlCl1NwCTePoGzZe2TTAnN13Y1LrzJEePT4ceikN9oQ2NBPbQgPYjoNDVVchhgbDpIerHg9LauLC5pYwU3bLlKgKae/Q/mX6XoX1uHIPcxFt6YT+rSFPecaFydfOZOPWfj593NyyBCe6mEs9atR2VoWom2EuqkwBkMTbYH9ohPvKn0Ibl+WL8lcRWVPocty6WzT78n5hMsRd9wtVT1NmZQ0SJgAVq5RpHheCptkHw+Fnlm+/ZiEgm1hYYFFIO5MknRyroZQ770Zs41QP1M4qeRQASbykGhe/fF+Y7+jVRTCwbcc0LVNhtzfCjLkhyNkl+tu6ewh+6nB03HpQi6qppF/MS7nzVs+pyij3/3+9VyslucQrRVeCpNi6NfzteQ3W/QU2vRKGzZ/9BhjfAhMn7pw2m6YmmDSptLTdr4USmu6VUdfrqHfUlJlRT59DQo+ocRNg9ZIwfkzXipDXDS/AuqWweWUY8G582qh343eBPd8UegrtdQy0H7RjkDNlysjjnh4YzjMjcXra3l4YylNllpG287Wt3PDwq5x+1JydTxyTJ4+M1NvXB4N5pjsoJu2kSSO9x/r7YWCg5LTtzdA+PTpuQ1OBqGpq1qQo7VD273viRGiOemgNDIR95zJhAowbtz1te/MQX37LHtn3nZ52cDAci1xaWmD8+OLTDg2F7zmX8eND+mLTDg+H/7UC0poPY9u2wtYcp+Nx48KxgFCtuW1b9nTFpm1u3v677+zu5YZ7ns/+v5uRFqjcOWLbtpDvbMzCb6OUtD094TvJZcqUkarZnh5s2zgm9fdyyC7jOCj1m0j9jxZ4jli3tmvH4Ha080kFzxGdW/pDMHbYbNonhd/qDfe8wA/veXEkGXDBr5/ELZwjvnz83nzphLm595v+ux/t3JPvHJF+PKvN3bXU0QK0At7V1eVlc+933cOpIvty6G7uD/7Q/S+/d196l/ukibnT/tWx7v097sPDYd8zZ+ZM23/Y4X7pH/7inZ1r3e//vvsu43Lvd1aT+4WtI8usptxpdxnn/ouPuP/5P93XPOt+5JG5086cueOxOOGE3GknT94x7Ukn5T9u6U49NX/aLVtG0n784/nTdnaOpP3CF/KnXbZsJO1Xv5o/7TPPjKS98MK8aZfeepfv/Y+3+tMrNrlfckn+/d5998h+r7gif9pbbx1Je/XV+dPeeONI2htvzJ/26qtH0t56a/60V1wxkvbuu/OnveSSkbQPPZQ/7YUXjqR95pm8aTs/d44/vWKT/2LRK37sWT/Jv98vfGFkv52d+dN+/OMjabdsyZ/21FO3J316xab8aU86yXcweXLutCecsGPaPOcIP/LIHdPuvXfutPPn75h2/vzcaffee8e0ZTpH9E+Y5Gu7ekbSjnKO2P4bcq/pOeLpFZt873+81Ts/d07etL/9xR3+9IpN/vSKTb7l/H/Kv9+HHhrJw1jOEWXW1dXlgAOt7vmvtyoBSoJl9+bfvnUd/P78keeDee5yl/8Z/q0DsNA4t3dTzqTDPV1MvPciZjx0DwxsDr2wcmmZFtribHwJfCga8yXHHVvrHvCh6/N8IBmrXSaPT3TVVKXd9PhKvnN5mKxszxrnRQo3MDxM5+a+oqqGUtVKc3oGaKtUxsrkgPapHJDqjDCh8cMDjQNUZyoyDtCzN8OGVdD++lDVlGoUOzwEa56G5X+C1YuiyRz7Q9HyYD8M94eZqYcG8aEBhof6aWZox+qn/jz/P+lVVTPnweFnwUHvyz7PUarIerAPfBgGovuDrPstvni7pLQFVIGl6tGtt5fFK17jX//nWS5670HM3z18d7OmRvXoMagC20G5irczZVSBFZw2BlVgnT1DXP/4mtDmY2pLziqwzu5e1vUO4y0tPLOyiwt+/SSXnHTAzv8zKRWqAuvcOkDnQPg/e2ZlF9/85cPZ/3chEVVgo6V9dlUXp/7Hg/zqK+8Y6bGYcY64/M4dq5V6WkaO2YTBfr54/FzOOfGA7Hko8zmis7uXdVv68ImTeGb1Zs6/6Wku+Zt5HNQejkv697v9s3357Rw8Z5ewg2qdI8pcBVbMOEAKgOpMvQ6EuH1gsLOP4eBZLTDQA/1bQhfzDS+GEY83LGVg2yYGhobBh+ntG+DJ18bTfPSnmXHY34A1NVzDOg3qJymlDJ5XywH39L87umIHoKynASuL+X7rvcF2MTQQYg2Z2RzgZ0A7MAh8y91/VdtcFS/nD6JpPExsDQsdofv4/idu33xFth/dA8ADfwIa76SqQf0krvS/O7piu8bX0xhXxXy/Se1ZqACo/AaBc939CTObDTxqZr9z9zzlwPUn1T137swp7N8+teBukkk7qdbTCS+lke7m6llndy8/+uNLHH/gTGZMmVBSV+JaDgNQj/+79SbO5zN9v6NTAFRm7r4aWB09XmNm64EZQKwCoJRzb3hih+fpdz+fPm4uUyaM2+FCqx9d7SV1VNdq69zcx1X3L+Oq+5ftsL6YwfOSeucdF2M5nyV9jKs4UACUwcyOB74GHAHsBrzP3W/OSHN2lGY28CRwjrs/lGVfRwDN7v5qpfNdDtkGxjrnbfuzX/tUXly3hcvvWrrD3c/GrX187KcP60Ib0Qkvmb5/+qHbS0njVEKQTv+75VdPwa2+3+wUAO1sCiGo+SlwU+ZGMzsduBQ4C1gEnAvcbmbz3L0zLd0M4DrgM1XIc1lkq+++/O6lOzxPv/tJL+rPJmk/ulqe8DSqa3VkO869A6EX0MTxoZdLHEs86+liXa/ifD7T95udeoHlYWZORgmQmS0CHnb3L0bPm4BXgcvd/eJo3QTgDuDH7v6zUd5jAmGqqZRpwIpa9ALL14NhaecWzr3hCa771NHMmNKSNQ3oQlsr6tFTHaMdZ6AmPbpEJFAvsAoxsxZC1dh3UuvcfdjMFgJvjtIYcA1w12jBT+QC4MLy57Z4+eq7U3c/f1yybkxtHqQy4txYM07yHeeNW/v545J1OtYiMaEAqDgzgWZgbcb6tcDrosfHAqcDT5nZKdG6M939abL7DqFKLWUasKIsuS2jVBFqZ3cvpxy2B6ALbT3JF7zGqVdYved1tEaxxx84a/v6ev8sIkmnAKjM3P1+oKmI9H3A9mFrzSxP6urJVd+tXl7xE6deYXHK62ga6bOINCIFQMVZDwwBHRnrO4A11c9O5ajRXHzFubFmnOg4i8SbAqAiuHu/mT0KnAjcDNsbQZ8IXFHDrNWELgBjV4lqkvbWiZxxzF50bu6jc3Nf3fcKi2sPtmw3CXH9LCJJpF5gGcxsKrB/9PRx4DzgbmCjuy+PusFfC3wOeIjQDf6DwOvcPbNtUCnvX5dzgUllVGouqDj1CotTXkfTSJ9F6oPakhVHvcDG5khCwJOSaqB8LfAJd7/BzGYBFxEGQnwCeFc5gh+RcqmHXmGFnrjrIa/l0kifReqD2pJVjgKgDO5+D5C3JbK7X0ECq7ykPKpRTVIPjdULPXHXQ17LpZE+i0ijUwAkUmXFzjAtIsmitmTVoQBIpMqqXU1SzcbqYz1x10vD+nK0u6iXzyLxo5uk6lAj6DqjRtDJUqlG0LXSKI2AG+17kXjJNy0RqAQoHzWCFpGaUCNgkbFTW7LqUAAkUkONVk0S5xO32l2IJIsCIJEa0ojb9UPtLqQeNdpNUj1RG6A6ozZA0ijiNoCb2l2IxJ/aAIlIzcWtdCvO1XciUryCZy0XERERaRQKgEREMqjdhUjjUxugOqM2QCIiIqUppg2QSoBEREQkcRQASdl0dvdy2R1L6OzurXVWRERE8lIAJGWTmv071ZVYRESkXikAkrqiUqT40ncnInGiAEjGpLO7l2dWdm1fgB2eF3sxVClSfOm7E5E40UCIMiaaPkBEROJIAZCMSTlm/9YklPGl705E4koBkIxJOaYPUCnSiLjNn6XvTkTiSgGQ1Fw5SpEaRaodzYL5HbEIgPTdiUhcKQCSsil1+gBNQhlf+u5EJK4UAEnZxG3273qhdjQipYtbtbHUDwVAUleSOAllo7SjSeJ3J7UXt2pjqR8KgKSuJLEUqVHa0STxuxOR+FIAJFJjakcjUhxVG0s5KAASEZFYaZRqY6ktBUAidUTtaERG1yjVxlJbCoBE6oja0YiMTtXGUg6aDFVEREQSRwGQiIjElqqNpVTm7rXOg6Qxs1agq6uri9bW1lpnR0REJDa6u7tpa2sDaHP37nxpVQIkIiIiiaMASERERBJHAZCIiIgkjgIgERERSRwFQAnQ2d3LZXcsobO7t9ZZERERqQsKgBIgNVtyau6crGkUJImISIIoABKgsCBJRESkUWgqjAal2ZJFRERyUwDUoAqZLfmMY/ZSkCQiIomkkaDrTLlGgs4sAco2W3K2ICndl048QBNziohIbBQzErRKgBpUIbMln3HMXiyY3wHkDpJEROpJZ3cv1y9azhnH7KUSahkTBUAJVkiQJCJST1IdNhbM71AAJGOiXmAJoNmSRUREdqQSoARob504alseBUkiUq/Uq1UqQY2g60y5GkGLiDSKy+5Yog4bUhA1ghYRkYahDhtSCQqARESkrqnDhlSCGkGLiIhI4igAEhGR2FCHDSkXNYKuM2oELSIiUppiGkGrBEhEREQSRwGQiIiIJI4CIBEREUkcBUAiIiKSOAqAREQkUTq7e7nsjiV0dvfWOitSQwqAREQkUVIzyqfmF5NkUgAkIiIiiaOpMEREpOFpRnnJpABIREQa3vWLlu80o/z5Nz29/bFmlE8eBUAiItLwNKO8ZFIAVGFm9hvgrcCd7n5qjbMjIpJImlFeMqkRdOX9APhYrTMhIiIiIxQAVZi73wNsrnU+REQk0IzyAjENgMxsmpl938xeMbMeM/uTmR1V5vc43sxuMbNVZuZmdkqOdGeb2ctm1mtmi8zs6HLmQ0REyqu9dSJfXnCgen0lXCwDIOAqYAFwJnAI8AdgoZntkS2xmR1rZuOzrJ9vZh053mMK8CRwdq5MmNnpwKXAN4HDo/S3m1l7EZ9FREREqix2AZCZTQI+APyDu//R3Ze6+zeApcDns6RvAq4Efm5mzWnr5wF3AR/P9j7ufpu7/7O7/yZPds4DfuzuV7v7YuAsYBvwqdI+nYiIiFRD7AIgQs+1ZiBzEpce4LjMxO4+DJwEHAZcZ2ZNZrYfIfi52d0vKSUTZtYCHAEszHivhcCbS9jf2Wa2GHiolPyIiIhI4WIXALn7ZuBB4F/MbHczazazjxKCjt1yvGYV8HZCgPRzQvCzkCwlRkWYSQjE1masXwvMTj0xs4XAr4CTzGyFmWUNjtz9SnefD6gNkYiISIXFdRygM4GfAiuBIeAx4BeEEpms3H25mZ0J3Au8BPydu3ulM+ru76j0e4iIiEhxYlcCBODuL7r7CcBUYI67Hw2MJwQ2WUWNnX8E3AJMBi4bYzbWE4KvzEbUHcCaMe5bREREKiiWAVCKu29199VmtgvwTuB/sqUzs5nAncBzwPuBE4HTzex7Y3jvfuDRaF+p92mKnj9Y6n5FRESk8mJZBWZm7wQM+AuwP/Bd4Hng6ixpm4DbgFeA0919EFhsZguAu8xspbvvVBpkZlOjfafMNbNDgY3uvjxadylwrZk9Qmi8fC6h+/xO+ShWd3f3WHchIiKSKEVdO909dgvwQeBFoA9YDVwBtOVJvwCYmGX9YcCeOV7zVsCzLNdkpPsiIbjqAxYBx4zxs+2R4321aNGiRYsWLYUte4x2vbUqtAOWIpiZAbtT3ukzpgErgD3LvN+k03EtPx3TytBxLT8d0/Ir1zGdBqwaraNTLKvAGln0ha0s5z5DTAXAZndX3VqZ6LiWn45pZei4lp+OafmV8ZgW9NpYN4IWERERKYUCIBEREUkcBUDJ0EeYsLWv1hlpMDqu5adjWhk6ruWnY1p+VT2magQtIiIiiaMSIBEREUkcBUAiIiKSOAqAREREJHEUAImIiEjiKABKADM728xeNrNeM1tkZkfXOk9xYWYXmNnDZrbZzDrN7GYzm5eRZqKZXWlmG8xsi5n92sw6apXnuDGz883Mzez7aet0TEtgZnuY2X9Fx63HzJ42syPTtpuZXWRmq6PtC83sgFrmuZ6ZWbOZfcvMlkXH60Uz+xdLG7FPx3R0Zna8md1iZqui3/opGdtHPYZmNsPMrjezbjPbZGY/iebsLJkCoAZnZqcTJm39JnA48CRwu5m11zRj8XECcCXwJsKccuOBP5jZlLQ0lwF/A5wWpd8duKnK+YwlMzsK+BzwVMYmHdMimdkuwAPAAPBuYD7wFeC1tGT/APw9cBZwDLCVcD6YWN3cxsY/Ap8nzPn4+uj5PwDnpKXRMR3dFMK15+wc2ws5htcDBxHOw+8Bjgd+NKZc1XpiUy2VXQgTtF6R9ryJMNXG+bXOWxwXYBZhor3jo+dtQD9walqa10Vp3lTr/NbzAkwFlgDvAO4Bvq9jOqbjeTFwX57tRpg8+qtp69qAXuBDtc5/PS7ArcBPMtb9GvgvHdOSj6kDp6Q9H/UYEoJPB45MS/MuYBjYvdS8qASogZlZC3AEsDC1zt2Ho+dvrlW+Yq4t+rsx+nsEoVQo/Rg/DyxHx3g0VwK/dfeFGet1TEvzt8AjZvarqLr2cTP7TNr2ucBsdjyuXYSbJB3X7P4EnGhmBwKY2RuB44Dbou06pmNXyDF8M7DJ3R9Je91CQgB0TKlvrMlQG9tMoBlYm7F+LeGOWopgZk3A94EH3P2ZaPVsoN/dN2UkXxttkyzM7EOEKtmjsmzWMS3NvoTqmkuBbxOO7f81s353v5aRY5ftfKDjmt3FQCvwvJkNEc6n/+Tu10fbdUzHrpBjOBvoTN/o7oNmtpExHGcFQCKFuxI4mHAHKCUysznAD4AF7t5b6/w0kCbgEXf/evT8cTM7mNCu4traZSvWPgicAXwEeBY4FPi+ma2KgkqJMVWBNbb1wBCQ2XumA1hT/ezEl5ldQWh49zZ3X5G2aQ3QYmbTM16iY5zbEUA78JiZDZrZIKGh899Hj9eiY1qK1cDijHXPAXtFj1PHTueDwn0XuNjdf+nuT7v7zwgN9C+ItuuYjl0hx3AN4ZyxnZmNA2YwhuOsAKiBuXs/8ChwYmpdVI1zIvBgrfIVJ1H3zCuA9wFvd/dlGUkeJfS6ST/G8wgXHR3j7O4EDiHcTaeWRwi9PFKPdUyL9wAwL2PdgcAr0eNlhItF+nFtJbSh0HHNbjKhnUm6IUaunTqmY1fIMXwQmG5mR6S97u2E72FRqW+sKrDGdylwrZk9AjwEnEvoknh1LTMVI1cSir/fC2w2s1R9c5e797h7l5n9BLg0qo/uBi4HHnT3P9cmy/XN3TcDz6SvM7OtwIZU2yod05JcBvzJzL4O3AgcDXw2WnD31FhL/2xmLxAuPN8CVgE31yLDMXAL8E9mtpxQBXYYcB7wU9AxLVQ0Xs/+aavmmtmhwEZ3Xz7aMXT358zs98CPzewsQieJK4BfuvuqkjNW6y5xWiq/EMaweAXoI0TLx9Q6T3FZCF0vsy2fSEszkRAobSSMX3ETMLvWeY/TQlo3eB3TMR3H9wBPE7oQPwd8JmO7ARcR7rh7CT1pDqx1vut1AaYROj68AvQALwL/H9CiY1rUcXxrjvPoNYUeQ0J118+BzUAXIQidOpZ8WbRjERERkcRQGyARERFJHAVAIiIikjgKgERERCRxFACJiIhI4igAEhERkcRRACQiIiKJowBIREREEkcBkIiIiCSOAiARkYiZ7WNmHg3TX6n3uMbMbq7U/kWkMAqARKRhRMGFZ1l+X+AuXgV2I2OuMhFpPJoMVUQaze+BT2as6yvkhe4+RJiPSEQanEqARKTR9Ln7mozlNYCoNOjzZnabmfWY2UtmdmrqhZlVYGa2i5ldb2brovQvmNkn09IfYmZ3Rds2mNmPopmvU9ubzexSM9sUbb+EMPEjaWmazOwCM1sW7efJ9DyJSGUoABKRpPkW8GvgjcD1wC/N7PV50s4H3g28Hvg8sB7AzKYAtwOvAUcBpwHvAK5Ie/1XgE8AnwKOI8xo/b6M97gA+BhwFnAQcBnwX2Z2whg+o4iMQrPBi0jDMLNrgI8CvRmbvu3u3zYzB/7T3T+f9po/A4+5+xfMbB9gGXCYuz9hZv8LrHf3T2V5r88A/weY4+5bo3UnAbcAu7v7WjNbBVzm7t+Nto+L9v+ou59iZhOAjcA73P3BtH1fBUx294+U47iIyM7UBkhEGs3dhJKadBvTHj+Yse1B4NAc+/oP4NdmdjjwB+Bmd/9TtO31wJOp4CfyAKFkfZ6Z9RIaVC9KbXT3QTN7hJFqsP2BycAdZjvUjLUAj+f6gCIydgqARKTRbHX3peXYkbvfZmZ7AycBC4A7zexKd/9qOfYPpNoLnQyszNhWUMNtESmN2gCJSNK8Kcvz53Ildvd17n6tu38UOBf4bLTpOeCNUVuglGOBYeAv7t4FrAaOSW2MqsCOSEu/mBDo7OXuSzOWV0v7eCJSCJUAiUijmWBmszPWDbr7+ujxaVE11P3AGcDRwN9l25GZXQQ8CjwLTADew0iwdD3wTeBaM/sGMAu4HPiZu6+N0vwAON/MXgCeB84Dpqf27+6bzex7wGVm1hTlqY0QSHW7+7UlHQERGZUCIBFpNO8ilLyk+wvwuujxhcCHgB9G6T7s7otz7Ksf+A6wD9AD3Be9FnffZmbvJAQ5DwPbCL3Lzkt7/b8T2gFdSygZ+inwG0KQk/IvwDpCb7B9gU3AY8C3C/7EIlI09QITkcSIeoG9z91vrnVeRKS21AZIREREEkcBkIiIiCSOqsBEREQkcVQCJCIiIomjAEhEREQSRwGQiIiIJI4CIBEREUkcBUAiIiKSOAqAREREJHEUAImIiEjiKAASERGRxPn/AetHBsIwecerAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 100\n",
    "else:\n",
    "    num_episodes = 100\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    #print('Episode ', i_episode)\n",
    "    # Initialize the environment and get it's state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        #print('t ', t)\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated = env.step(action.item())\n",
    "        reward = torch.tensor([np.float32(reward)], device=device)\n",
    "        done = terminated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        #print(state, action, next_state, reward)\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            if len(episode_returns_averaged) == 0:\n",
    "                episode_returns_averaged.append(lazy_reward)\n",
    "            else:\n",
    "                episode_returns_averaged.append(episode_returns_averaged[-1] * (1 - EXPONENTIAL_AVG_FACTOR) + env.budget * (EXPONENTIAL_AVG_FACTOR))\n",
    "            episode_returns.append(env.budget)\n",
    "            lazy_bound.append(lazy_reward)\n",
    "            optimal_bound.append(optimal_reward)\n",
    "            plot_metrics()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "print('current greed rate: ', EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY))\n",
    "print('current avg reward: ', episode_returns_averaged[-1] )\n",
    "plot_metrics(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
