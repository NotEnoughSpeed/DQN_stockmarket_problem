{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions, layer_depth, layers = 1):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, layer_depth)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(layers):\n",
    "            self.layers.append(nn.Linear(layer_depth, layer_depth))\n",
    "        #self.layer2 = nn.Linear(layer_depth, layer_depth)\n",
    "        self.layer3 = nn.Linear(layer_depth, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        for i in range(len(self.layers)):\n",
    "            x = F.relu(self.layers[i](x))\n",
    "        #x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "df = pd.read_csv('stockmarket_data.csv', decimal='.')\n",
    "df_dis = df[(df['stock'] == 'DIS')]\n",
    "df_msft = df[(df['stock'] == 'MSFT')]\n",
    "df_vow3 = df[(df['stock'] == 'VOW3')]\n",
    "df_jnj = df[(df['stock'] == 'JNJ')]\n",
    "df_r6C0 = df[(df['stock'] == 'R6C0')]\n",
    "df_date = df['Date'].unique()\n",
    "\n",
    "data = df.to_numpy().T\n",
    "\n",
    "companies = ['MSFT', 'VOW3', 'JNJ', 'DIS', 'R6C0']\n",
    "stockmarket_data = np.array([[[0],[0],[0],[0],[0],[0]]])\n",
    "bond_value = 1\n",
    "\n",
    "for i in range(len(df_date)):\n",
    "    date = df_date[i]\n",
    "    #print('date', date)\n",
    "    row_dis = df_dis[(df_dis['Date'] == date)]\n",
    "    row_msft = df_msft[(df_msft['Date'] == date)]\n",
    "    row_vow3 = df_vow3[(df_vow3['Date'] == date)]\n",
    "    row_jnj = df_jnj[(df_jnj['Date'] == date)]\n",
    "    row_r6C0 = df_r6C0[(df_r6C0['Date'] == date)]\n",
    "\n",
    "    if len(row_dis) * len(row_msft) * len(row_vow3) * len(row_jnj) * len(row_r6C0) != 0:\n",
    "        bond_value *= 1.00005\n",
    "        #print(np.array([[row_dis['Close'], row_msft['Close'], row_vow3['Close'], row_jnj['Close'], row_r6C0['Close']]]))\n",
    "        stockmarket_data = np.concatenate((stockmarket_data,\n",
    "                                            np.array([[[bond_value], row_dis['Close'], row_msft['Close'], row_vow3['Close'], row_jnj['Close'], row_r6C0['Close']]])), axis=0)\n",
    "    '''else:\n",
    "        print('date', date)\n",
    "        print('DIS', row_dis)\n",
    "        print('MSFT ', row_msft)\n",
    "        print('VOW3 ',row_vow3)\n",
    "        print('JNJ ',row_jnj)\n",
    "        print('R6C0 ',row_r6C0)'''\n",
    "stockmarket_data = stockmarket_data.reshape((len(stockmarket_data),6))\n",
    "stockmarket_data = np.delete(stockmarket_data, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spielumgebung definieren\n",
    "class stockmarket():\n",
    "\n",
    "    #Initialisierung des Spiels\n",
    "    def __init__(self, stockmarketdata, start_budget, last_day):\n",
    "        self.stockmarketdata = stockmarketdata\n",
    "        self.start_budget = start_budget\n",
    "        self.budget = start_budget\n",
    "        self.day = 0\n",
    "        self.num_days = len(stockmarketdata)\n",
    "        #self.actionspace = np.array(range(2**len(stockmarketdata[0])))\n",
    "        #self.actionspace_length = 2**len(stockmarketdata[0])\n",
    "        self.actionspace = np.array(range(len(stockmarketdata[0])))\n",
    "        self.actionspace_length = len(stockmarketdata[0])\n",
    "        self.last_day = last_day\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        terminated = False\n",
    "        reward = 0\n",
    "        roi = 0\n",
    "\n",
    "        '''#action aus 0-64 in array aus 6 Nullen und Einsen umwandeln -> 0 = nicht gekauft, 1 = gekauft\n",
    "        portfolio_action = []\n",
    "\n",
    "        for i in range(self.actionspace_length):\n",
    "            portfolio_action.append(action % 2)\n",
    "            action = math.floor(action / 2)'''\n",
    "\n",
    "        self.day += 1\n",
    "\n",
    "        if self.day == self.num_days or self.budget == 0 or self.day >= self.last_day:\n",
    "            #run is over\n",
    "            terminated = True\n",
    "\n",
    "            return np.array(self.state), 0, terminated\n",
    "        else:\n",
    "            #Profit berechnen\n",
    "\n",
    "            '''for i in range(len(self.stockmarketdata[0])):\n",
    "                reward += portfolio_action[i] * (self.budget * (self.stockmarketdata[self.day][i] / self.stockmarketdata[self.day - 1][i]) - self.budget)\n",
    "\n",
    "            if sum(portfolio_action) > 0:\n",
    "                reward /= sum(portfolio_action)'''\n",
    "            \n",
    "            reward = (self.budget * (self.stockmarketdata[self.day][action] / self.stockmarketdata[self.day - 1][action]) - self.budget)\n",
    "            roi += (self.stockmarketdata[self.day][action] / self.stockmarketdata[self.day - 1][action])\n",
    "\n",
    "        reward = np.float32(reward)\n",
    "\n",
    "        #reward -= self.budget\n",
    "\n",
    "        self.budget += reward\n",
    "\n",
    "        #print('reward ', reward)\n",
    "        #print('budget ', self.budget)\n",
    "\n",
    "        #self.state = np.concatenate(([self.budget],self.stockmarketdata[self.day]), axis=0)\n",
    "        self.state = self.stockmarketdata[self.day]\n",
    "        \n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated\n",
    "\n",
    "    def reset(self):\n",
    "        #state = [budget, stockmarketdata]\n",
    "        #self.state = np.concatenate(([self.budget],self.stockmarketdata[0]), axis=0)\n",
    "        self.state = self.stockmarketdata[0]\n",
    "        self.day = 0\n",
    "        self.budget = self.start_budget\n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = stockmarket(stockmarket_data, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal reward:  378.2405787009821\n",
      "lazy reward:  104.71369130729852\n"
     ]
    }
   ],
   "source": [
    "#calculate optimal and \"lazy\" reward\n",
    "optimal_reward = env.start_budget\n",
    "lazy_reward = env.start_budget\n",
    "\n",
    "upper_bound = min(len(env.stockmarketdata), env.last_day)\n",
    "\n",
    "for t in range(upper_bound):\n",
    "    if t == 0:\n",
    "        t = 1\n",
    "\n",
    "    max_reward = 0\n",
    "\n",
    "    for i in range(len(env.stockmarketdata[0])):\n",
    "        #lazy reward picks bond + all stocks equally\n",
    "        lazy_reward += (1 / env.actionspace_length) * (lazy_reward * (env.stockmarketdata[t][i] / env.stockmarketdata[t - 1][i]) - lazy_reward)\n",
    "\n",
    "        #optimal reward stock/bond with biggest reward\n",
    "        reward = 1 * (optimal_reward * (env.stockmarketdata[t][i] / env.stockmarketdata[t - 1][i]) - optimal_reward)\n",
    "\n",
    "        if reward > max_reward:\n",
    "            max_reward = reward\n",
    "\n",
    "    optimal_reward += max_reward\n",
    "\n",
    "print('optimal reward: ', optimal_reward)\n",
    "print('lazy reward: ', lazy_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.099\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.actionspace_length\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "layer_depth = 1000\n",
    "layers = 1\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions, layer_depth, layers).to(device)\n",
    "target_net = DQN(n_observations, n_actions, layer_depth, layers).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[np.random.choice(env.actionspace)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "episode_returns = []\n",
    "episode_returns_averaged = []\n",
    "lazy_bound = []\n",
    "optimal_bound = []\n",
    "EXPONENTIAL_AVG_FACTOR = 0.02\n",
    "\n",
    "\n",
    "def plot_metrics(show_result=False):\n",
    "    plt.figure(1)\n",
    "    returns_t = torch.tensor(episode_returns, dtype=torch.float)\n",
    "    returns_avg_t = torch.tensor(episode_returns_averaged, dtype=torch.float)\n",
    "    lazy_bound_t = torch.tensor(lazy_bound, dtype=torch.float)\n",
    "    optimal_bound_t = torch.tensor(optimal_bound, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Returns')\n",
    "    plt.plot(returns_t.numpy(), '+')\n",
    "    plt.plot(returns_avg_t.numpy())\n",
    "    plt.plot(lazy_bound_t.numpy(), 'r--')\n",
    "    plt.plot(optimal_bound_t.numpy(), 'g--')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    '''\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())'''\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "    #print('model got optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (layer1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  )\n",
      "  (layer3): Linear(in_features=5, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(policy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "EPS_START = 0.9\n",
    "EPS_END = 0.0005\n",
    "EPS_DECAY = 5000\n",
    "EXPONENTIAL_AVG_FACTOR = 0.02\n",
    "print(EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "current greed rate:  0.12223408727133314\n",
      "current avg reward:  106.21789987417932\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 100\n",
    "else:\n",
    "    num_episodes = 100\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    #print('Episode ', i_episode)\n",
    "    # Initialize the environment and get it's state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        #print('t ', t)\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated = env.step(action.item())\n",
    "        reward = torch.tensor([np.float32(reward)], device=device)\n",
    "        done = terminated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        #print(state, action, next_state, reward)\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            if len(episode_returns_averaged) == 0:\n",
    "                episode_returns_averaged.append(lazy_reward)\n",
    "            else:\n",
    "                episode_returns_averaged.append(episode_returns_averaged[-1] * (1 - EXPONENTIAL_AVG_FACTOR) + env.budget * (EXPONENTIAL_AVG_FACTOR))\n",
    "            episode_returns.append(env.budget)\n",
    "            lazy_bound.append(lazy_reward)\n",
    "            optimal_bound.append(optimal_reward)\n",
    "            plot_metrics()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "print('current greed rate: ', EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY))\n",
    "print('current avg reward: ', episode_returns_averaged[-1] )\n",
    "plot_metrics(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
